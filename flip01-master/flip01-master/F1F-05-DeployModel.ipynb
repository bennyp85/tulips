{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP(01):  Advanced Data Science\n",
    "**(Module F: MLflow)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "- If you found any issue/bug for this document, please submit an issue at [tulip lab/flip01](https://github.com/tulip-lab/flip01/issues)\n",
    "\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2022 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Session 04 - Deploy the Model to Seldon Core or KServe (experimental)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training and testing our model, we are now ready to deploy it to production. MLflow allows you to serve your model using MLServer, which is already used as the core Python inference server in Kubernetes-native frameworks including Seldon Core and KServe (formerly known as KFServing). Therefore, we can leverage this support to build a Docker image compatible with these frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Note that this an optional step, which is currently only available for Python models. Besides this, it’s also worth noting that:\n",
    "\n",
    "* This feature is experimental and is subject to change.\n",
    "\n",
    "* MLServer requires Python 3.7 or above.\n",
    "\n",
    "* This step requires some basic Kubernetes knowledge, including familiarity with kubectl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a Docker image containing our model, we can use the mlflow models build-docker subcommand, alongside the *--enable-mlserver* flag. For example, to build a image named *my-docker-image*, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow models build-docker \\\n",
    "  -m /Users/mlflow/mlflow-prototype/mlruns/0/7c1a0d5c42844dcdb8f5191146925174/artifacts/model \\\n",
    "  -n my-docker-image \\\n",
    "  --enable-mlserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our image built, the next step will be to deploy it to our cluster. One way to do this is by applying the respective Kubernetes manifests through the kubectl CLI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f my-manifest.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step assumes that you’ve got kubectl access to a Kubernetes cluster already setup with Seldon Core. To read more on how to set this up, you can refer to the Seldon Core quickstart guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: mlflow-model\n",
    "spec:\n",
    "  predictors:\n",
    "    - name: default\n",
    "      annotations:\n",
    "        seldon.io/no-engine: \"true\"\n",
    "      graph:\n",
    "        name: mlflow-model\n",
    "        type: MODEL\n",
    "      componentSpecs:\n",
    "        - spec:\n",
    "            containers:\n",
    "              - name: mlflow-model\n",
    "                image: my-docker-image\n",
    "                imagePullPolicy: IfNotPresent\n",
    "                securityContext:\n",
    "                  runAsUser: 0\n",
    "                ports:\n",
    "                  - containerPort: 8080\n",
    "                    name: http\n",
    "                    protocol: TCP\n",
    "                  - containerPort: 8081\n",
    "                    name: grpc\n",
    "                    protocol: TCP\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
