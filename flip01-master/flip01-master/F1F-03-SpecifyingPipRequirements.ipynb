{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP(01):  Advanced Data Science\n",
    "**(Module F: MLflow)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "- If you found any issue/bug for this document, please submit an issue at [tulip lab/flip01](https://github.com/tulip-lab/flip01/issues)\n",
    "\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2022 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Session 03 - Specifying pip requirements using pip_requirements and extra_pip_requirements\n",
    "\n",
    "### Specifying pip requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example demonstrates how to specify pip requirements using `pip_requirements` and\n",
    "`extra_pip_requirements` when logging a model via `mlflow.*.log_model`.\n",
    "\"\"\"\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def read_lines(path):\n",
    "    with open(path) as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "\n",
    "def get_pip_requirements(run_id, artifact_path, return_constraints=False):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    req_path = client.download_artifacts(run_id, f\"{artifact_path}/requirements.txt\")\n",
    "    reqs = read_lines(req_path)\n",
    "\n",
    "    if return_constraints:\n",
    "        con_path = client.download_artifacts(run_id, f\"{artifact_path}/constraints.txt\")\n",
    "        cons = read_lines(con_path)\n",
    "        return set(reqs), set(cons)\n",
    "\n",
    "    return set(reqs)\n",
    "\n",
    "\n",
    "def main():\n",
    "    iris = load_iris()\n",
    "    dtrain = xgb.DMatrix(iris.data, iris.target)\n",
    "    model = xgb.train({}, dtrain)\n",
    "\n",
    "    xgb_req = f\"xgboost=={xgb.__version__}\"\n",
    "    sklearn_req = f\"scikit-learn=={sklearn.__version__}\"\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        # Default (both `pip_requirements` and `extra_pip_requirements` are unspecified)\n",
    "        artifact_path = \"default\"\n",
    "        mlflow.xgboost.log_model(model, artifact_path)\n",
    "        pip_reqs = get_pip_requirements(run_id, artifact_path)\n",
    "        assert pip_reqs.issuperset([\"mlflow\", xgb_req]), pip_reqs\n",
    "\n",
    "        # Overwrite the default set of pip requirements using `pip_requirements`\n",
    "        artifact_path = \"pip_requirements\"\n",
    "        mlflow.xgboost.log_model(model, artifact_path, pip_requirements=[sklearn_req])\n",
    "        pip_reqs = get_pip_requirements(run_id, artifact_path)\n",
    "        assert pip_reqs == {\"mlflow\", sklearn_req}, pip_reqs\n",
    "\n",
    "        # Add extra pip requirements on top of the default set of pip requirements\n",
    "        # using `extra_pip_requirements`\n",
    "        artifact_path = \"extra_pip_requirements\"\n",
    "        mlflow.xgboost.log_model(model, artifact_path, extra_pip_requirements=[sklearn_req])\n",
    "        pip_reqs = get_pip_requirements(run_id, artifact_path)\n",
    "        assert pip_reqs.issuperset([\"mlflow\", xgb_req, sklearn_req]), pip_reqs\n",
    "\n",
    "        # Specify pip requirements using a requirements file\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".requirements.txt\") as f:\n",
    "            f.write(sklearn_req)\n",
    "            f.flush()\n",
    "\n",
    "            # Path to a pip requirements file\n",
    "            artifact_path = \"requirements_file_path\"\n",
    "            mlflow.xgboost.log_model(model, artifact_path, pip_requirements=f.name)\n",
    "            pip_reqs = get_pip_requirements(run_id, artifact_path)\n",
    "            assert pip_reqs == {\"mlflow\", sklearn_req}, pip_reqs\n",
    "\n",
    "            # List of pip requirement strings\n",
    "            artifact_path = \"requirements_file_list\"\n",
    "            mlflow.xgboost.log_model(\n",
    "                model, artifact_path, pip_requirements=[xgb_req, f\"-r {f.name}\"]\n",
    "            )\n",
    "            pip_reqs = get_pip_requirements(run_id, artifact_path)\n",
    "            assert pip_reqs == {\"mlflow\", xgb_req, sklearn_req}, pip_reqs\n",
    "\n",
    "        # Using a constraints file\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".constraints.txt\") as f:\n",
    "            f.write(sklearn_req)\n",
    "            f.flush()\n",
    "\n",
    "            artifact_path = \"constraints_file\"\n",
    "            mlflow.xgboost.log_model(\n",
    "                model, artifact_path, pip_requirements=[xgb_req, f\"-c {f.name}\"]\n",
    "            )\n",
    "            pip_reqs, pip_cons = get_pip_requirements(\n",
    "                run_id, artifact_path, return_constraints=True\n",
    "            )\n",
    "            assert pip_reqs == {\"mlflow\", xgb_req, \"-c constraints.txt\"}, pip_reqs\n",
    "            assert pip_cons == {sklearn_req}, pip_cons\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
