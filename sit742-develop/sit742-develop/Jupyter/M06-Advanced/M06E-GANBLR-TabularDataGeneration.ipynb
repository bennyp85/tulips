{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Cloud-First](https://github.com/tulip-lab/sit742/blob/develop/Jupyter/image/CloudFirst.png?raw=1)\n",
        "\n",
        "\n",
        "# SIT742: Modern Data Science\n",
        "**(Module: Generative Adversarial Network)**\n",
        "\n",
        "---\n",
        "- Materials in this module include resources collected from various open-source online repositories.\n",
        "- You are free to use, change and distribute this package.\n",
        "- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n",
        "\n",
        "\n",
        "Prepared by **SIT742 Teaching Team**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Session 6E: Tabular Data Generation on GAN"
      ],
      "metadata": {
        "id": "tWehnUNdaGV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare for the used library"
      ],
      "metadata": {
        "id": "faohn97-ajws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCnPD2GpUP5j"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/chriszhangpodo/GANBLR_LIBRARY.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run setup file to install the modules"
      ],
      "metadata": {
        "id": "CgMHdTr_at9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GANBLR_LIBRARY/setup.py install"
      ],
      "metadata": {
        "id": "NzfJMPUhUW0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pgmpy"
      ],
      "metadata": {
        "id": "zQnmpg91cwLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy and Move the installed library and modules to default work path"
      ],
      "metadata": {
        "id": "LbE5Kq0Kazwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/GANBLR_LIBRARY/ganblr /content/ganblr"
      ],
      "metadata": {
        "id": "tk9OtUzqUX5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction of Tabular Data Generation"
      ],
      "metadata": {
        "id": "Wcw6PfcLa67i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabular data generation refers to the process of creating synthetic data that is organized in rows and columns, similar to how data is structured in spreadsheets or relational databases. There are several reasons why generating tabular data can be valuable:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Anonymization**: Real datasets often contain sensitive information that cannot be shared publicly or even internally without risking privacy breaches. Generating synthetic data can help create datasets that mimic the properties of the original data without exposing sensitive details.\n",
        "2.   **System Testing**: Synthetic data can be used to stress test systems, ensuring they can handle large volumes of data and operate correctly under various conditions.\n",
        "\n",
        "1.   **Model Training**: Synthetic data can be used to train machine learning models when real data is scarce, incomplete, or imbalanced. It helps in creating balanced datasets, especially in scenarios where certain classes are underrepresented.\n",
        "2.   **Data Augmentation and Enhancing Datasets**: Synthetic data can be used to augment real datasets, increasing the size and diversity of the training data for machine learning models.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ChAkFcgabF8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Difference between image data generation and tabular data generation"
      ],
      "metadata": {
        "id": "_G2quySWbwb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is the tabular data set, check it data types and also the structure\n",
        "from ganblr import get_demo_data\n",
        "from ganblr.models import GANBLR\n",
        "\n",
        "df = get_demo_data('adult')\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "JDGxIXJ_a6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is the image data set, check it data types and compare to the above tabular data\n",
        "from keras.datasets.mnist import load_data\n",
        "from numpy import expand_dims\n",
        "\n",
        "def load_real_samples():\n",
        " # load mnist dataset\n",
        " (trainX, _), (_, _) = load_data()\n",
        " # expand to 3d, e.g. add channels dimension\n",
        " X = expand_dims(trainX, axis=-1)\n",
        " # convert from unsigned ints to floats\n",
        " X = X.astype('float32')\n",
        " # scale from [0,255] to [0,1]\n",
        " X = X / 255.0\n",
        " return X\n",
        "\n",
        "dataset = load_real_samples()"
      ],
      "metadata": {
        "id": "MJJv8CIQUhC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "def show_images(examples, n):\n",
        "    # plot images\n",
        "    for i in range(n * n):\n",
        "        # define subplot\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        # turn off axis\n",
        "        pyplot.axis('off')\n",
        "        # plot raw pixel data\n",
        "        pyplot.imshow(examples[i])\n",
        "    pyplot.show()\n",
        "\n",
        "Sample_Original = dataset[np.random.choice(dataset.shape[0], size=25, replace=False)]\n",
        "show_images(Sample_Original, 1)"
      ],
      "metadata": {
        "id": "QY1QTniHeLjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we could see, the Structure and Representation are different between image data and tabular data.\n",
        "Using default GAN is not suitable for generating the tabular data due to below reasons:\n",
        "\n",
        "\n",
        "\n",
        "1.   Tabular data has mixture data type. Categorical and Numerical.\n",
        "2.   Tabular data is 2D and Image is 3D as default. The data value in Image data (pixel value) could indicate the data pattern obviously (direct shape recognized by human). It is quite hard to directly capture the pattern by observation on tabular data.\n",
        "1.   How to define the quality of the Tabular data? Image data could be viewed easily for its quality (looks like or dislike).\n",
        "\n",
        "\n",
        "\n",
        "Therefore, we need a new structure of the GAN to generate the tabular data well.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NHUkB5hHe3uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Different methods on tabular data generation"
      ],
      "metadata": {
        "id": "9621PjbPg2Pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian Network for Tabular data Generation"
      ],
      "metadata": {
        "id": "z-8QD_rxg_af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a student - grade bayesian network\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1IRSEJSxxG5lOkYq8q0ocEnYTXSfqGnt9)\n"
      ],
      "metadata": {
        "id": "udWBt8QunhaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.utils import get_example_model\n",
        "from pgmpy.sampling import BayesianModelSampling\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Defining the model structure. We can define the network by just passing a list of edges.\n",
        "model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('I', 'S')])\n",
        "\n",
        "# Defining individual CPDs.\n",
        "cpd_d = TabularCPD(variable='D', variable_card=2, values=[[0.6], [0.4]])\n",
        "cpd_i = TabularCPD(variable='I', variable_card=2, values=[[0.7], [0.3]])\n",
        "\n",
        "# The representation of CPD in pgmpy is a bit different than the CPD shown in the above picture. In pgmpy the colums\n",
        "# are the evidences and rows are the states of the variable. So the grade CPD is represented like this:\n",
        "#\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "#    | diff    | intel_0 | intel_0 | intel_1 | intel_1 |\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "#    | intel   | diff_0  | diff_1  | diff_0  | diff_1  |\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "#    | grade_0 | 0.3     | 0.05    | 0.9     | 0.5     |\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "#    | grade_1 | 0.4     | 0.25    | 0.08    | 0.3     |\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "#    | grade_2 | 0.3     | 0.7     | 0.02    | 0.2     |\n",
        "#    +---------+---------+---------+---------+---------+\n",
        "\n",
        "cpd_g = TabularCPD(variable='G', variable_card=3,\n",
        "                   values=[[0.3, 0.05, 0.9,  0.5],\n",
        "                           [0.4, 0.25, 0.08, 0.3],\n",
        "                           [0.3, 0.7,  0.02, 0.2]],\n",
        "                  evidence=['I', 'D'],\n",
        "                  evidence_card=[2, 2])\n",
        "\n",
        "cpd_l = TabularCPD(variable='L', variable_card=2,\n",
        "                   values=[[0.1, 0.4, 0.99],\n",
        "                           [0.9, 0.6, 0.01]],\n",
        "                   evidence=['G'],\n",
        "                   evidence_card=[3])\n",
        "\n",
        "cpd_s = TabularCPD(variable='S', variable_card=2,\n",
        "                   values=[[0.95, 0.2],\n",
        "                           [0.05, 0.8]],\n",
        "                   evidence=['I'],\n",
        "                   evidence_card=[2])\n",
        "\n",
        "# Associating the CPDs with the network\n",
        "model.add_cpds(cpd_d, cpd_i, cpd_g, cpd_l, cpd_s)\n",
        "\n",
        "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly\n",
        "# defined and sum to 1.\n",
        "model.check_model()"
      ],
      "metadata": {
        "id": "fDIBru5Xg-y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "# draw model in graph\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, node_color='#00b4d9', pos=pos, with_labels=True)"
      ],
      "metadata": {
        "id": "zx6jh08ajdg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create synthetic data\n",
        "samples = BayesianModelSampling(model).forward_sample(size=int(100))\n",
        "samples.head()"
      ],
      "metadata": {
        "id": "FXn4m24slZVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. GANBLR: New State of Art for Tabular Data Generation\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1ceKcsjZntT9dy3eYjjdY_vzUGsERYEog)"
      ],
      "metadata": {
        "id": "3YJxYmo6k-HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The differences of GANBLR comparing to common GAN models are:\n",
        "\n",
        "\n",
        "1.   The input to generator is the actual original data not random noise\n",
        "2.   The generator is a discriminatively trained bayesian network learned from the given data.\n",
        "1.   Objective function will have the conditional log-likelihood from the generator\n",
        "\n",
        "Therefore, the better trained generator from GANBLR, the better quality of the synthetic data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7HQpHc8CqfkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the load adult data into train and test for generation\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
      ],
      "metadata": {
        "id": "Qfi5osPHg8zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "36JbyJSHrnOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the ganblr with training data for generating the synthetic data\n",
        "from ganblr.models import GANBLR\n",
        "model = GANBLR()\n",
        "model.fit(X_train, y_train, k = 0, epochs = 10, batch_size=64)"
      ],
      "metadata": {
        "id": "3ZN1MGcrrpxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is ready, we can use `GANBLR.sample` method to sample some synthetic data.\n",
        "\n",
        "We can use the `size` parameter to specify the number of samples we want to generate. If we do not specify, it will generate the same number as the training data."
      ],
      "metadata": {
        "id": "VFGlK7oer9a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 1000\n",
        "\n",
        "syn_data = model.sample(size)"
      ],
      "metadata": {
        "id": "XcAjkGeJr58N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(data = syn_data, columns=df.columns).head(10)"
      ],
      "metadata": {
        "id": "19i0mtAir_XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, as we did in our paper, we will perform a simple TSTR(Train on Synthetic, Test on Real) evaluation to demonstrate the performance of our generated data.\n",
        "\n",
        "We will evaluate on three models from sklearn, `LogisticRegression`, `RandomForest`, and `MLPClassifier`.\n",
        "\n",
        "TRTR(Train on Real, Test on Real) will be used as the baseline for comparison."
      ],
      "metadata": {
        "id": "ISBKIIi8sGF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_score_lr = model.evaluate(X_test, y_test, model='lr')\n",
        "acc_score_mlp = model.evaluate(X_test, y_test, model='mlp')\n",
        "acc_score_rf = model.evaluate(X_test, y_test, model='rf')"
      ],
      "metadata": {
        "id": "nKppJNLusiT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "lbe = LabelEncoder()\n",
        "X_train_ohe = ohe.fit_transform(X_train)\n",
        "X_test_ohe = ohe.transform(X_test)\n",
        "y_train_lbe = lbe.fit_transform(y_train)\n",
        "y_test_lbe = lbe.transform(y_test)\n",
        "\n",
        "trtr_score_lr  = LogisticRegression().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)\n",
        "trtr_score_rf  = RandomForestClassifier().fit(X_train, y_train_lbe).score(X_test, y_test_lbe)\n",
        "trtr_score_mlp = MLPClassifier().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)"
      ],
      "metadata": {
        "id": "yZJwUlF-sKe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_evaluate = pd.DataFrame([\n",
        "    ['TSTR', acc_score_lr, acc_score_rf, acc_score_mlp],\n",
        "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp]\n",
        "], columns=['Evaluated Item', 'LR', 'RF', 'MLP'])\n",
        "df_evaluate"
      ],
      "metadata": {
        "id": "5x-_AOU9sNO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to understand the results?\n",
        "\n",
        "\n",
        "1.   TRTR means: using real data to train the model and test on the real data as well -- common way to do ML task, the result here indicates the best outcome of doing ML task from used model (under same condiction of parameter and training iterations).\n",
        "2.   TSTR means: using synthetic data to train the model and test on the real data -- if the quality of the synthetic data is good, it should be fully workable by replacing the original data on the model training and the testing results from original data is also close to the TSTR.\n",
        "\n",
        "How good our GANBLR is? you could see the TSTR and TRTR is really close each other, that is why we call it is the current benchmark!\n",
        "\n"
      ],
      "metadata": {
        "id": "tYUC7qpvtEEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some other tabular data generators:\n",
        "\n",
        "\n",
        "\n",
        "1.   CTGAN: https://github.com/sdv-dev/CTGAN\n",
        "2.   TVAE: https://github.com/sdv-dev/CTGAN\n",
        "1.   PATE-GAN: https://github.com/BorealisAI/private-data-generation\n",
        "2.   TABLEGAN: https://github.com/mahmoodm2/tableGAN\n",
        "\n",
        "You could explore the above generators and enjoy the tabular data generation!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PReA1ZU_uCDN"
      }
    }
  ]
}