{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "247sdGbxuplM"
      },
      "source": [
        "# SIT742: Modern Data Science\n",
        "**(Module: Big Data)**\n",
        "\n",
        "---\n",
        "- Materials in this module include resources collected from various open-source online repositories.\n",
        "- You are free to use, change and distribute this package.\n",
        "- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n",
        "\n",
        "\n",
        "Prepared by **SIT742 Teaching Team**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Session 6D: Generative Adversaial Network on Image Data Generation\n",
        "\n",
        "In this session, we will learn how to use GAN to do image generation\n",
        "\n",
        "\n",
        "\n",
        "### Content\n",
        "\n",
        "\n",
        "1. `GAN` Basics\n",
        "\n",
        "2. Loading `Image` Data\n",
        "\n",
        "3. Data Generation through `GAN`\n",
        "\n",
        "4. Image processing and ploting.\n",
        "\n",
        "\n",
        "\n",
        "**Note**: The data available on those service might be changing, so you need to adjust the code to accommodate those changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tFmnvxKuplO"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV3ZvCZRGDgI"
      },
      "source": [
        "<a id = \"cell_data\"></a>\n",
        "### 1. Data Loading\n",
        "\n",
        "Mnist Dataset is large database of handwritten digits that is commonly used for training various image processing systems. The MNIST database contains 60,000 training images and 10,000 testing images.\n",
        "\n",
        "We are going to use the training images for this experiment.\n",
        "You can download this sample data set from `keras.datasets.mnist`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "def load_real_samples():\n",
        " # load mnist dataset\n",
        " (trainX, _), (_, _) = load_data()\n",
        " # expand to 3d, e.g. add channels dimension\n",
        " X = expand_dims(trainX, axis=-1)\n",
        " # convert from unsigned ints to floats\n",
        " X = X.astype('float32')\n",
        " # scale from [0,255] to [0,1]\n",
        " X = X / 255.0\n",
        " return X\n",
        "\n",
        "dataset = load_real_samples()"
      ],
      "metadata": {
        "id": "gzPjmZVhjiDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_2YypsKHRgW"
      },
      "source": [
        "View some images in this sample data set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "i2fF1JxacffQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRG3BqOSPin-"
      },
      "outputs": [],
      "source": [
        "def show_images(examples, n):\n",
        "    # plot images\n",
        "    for i in range(n * n):\n",
        "        # define subplot\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        # turn off axis\n",
        "        pyplot.axis('off')\n",
        "        # plot raw pixel data\n",
        "        pyplot.imshow(examples[i])\n",
        "    pyplot.show()\n",
        "\n",
        "Sample_Original = dataset[np.random.choice(dataset.shape[0], size=25, replace=False)]\n",
        "show_images(Sample_Original, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7K15J-zGAl7"
      },
      "source": [
        "<a id = \"cell_GAN\"></a>\n",
        "### 2. GAN Model Construction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1URRiWgWq2Dmhoj2Jl55XbieDjdtaYL_O)"
      ],
      "metadata": {
        "id": "SdOlN0-AuP6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODwUgId8uplR"
      },
      "source": [
        "For GAN, it has two parts working together, `generator` and `discriminator`.\n",
        "How to Define Generator and Discriminator network architecture?\n",
        "\n",
        "\n",
        "1.   Define the Discriminator as a classification NN\n",
        "2.   Define the Generator based on the input and output dimension\n",
        "\n",
        "Then how does the GAN get trained?\n",
        "\n",
        "1.   Train the Generator model to generate the fake data that can fool Discriminator\n",
        "2.   Train the Discriminator model to distinguish real vs fake data\n",
        "1.   Continue the training for several epochs and save the Generator model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwtJQPBcuplR"
      },
      "outputs": [],
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        " model = Sequential()\n",
        " model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        " model.add(LeakyReLU(alpha=0.2))\n",
        " model.add(Dropout(0.4))\n",
        " model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        " model.add(LeakyReLU(alpha=0.2))\n",
        " model.add(Dropout(0.4))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(1, activation='sigmoid'))\n",
        " # compile model\n",
        " opt = Adam(lr=0.0002, beta_1=0.5)\n",
        " model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        " return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w-AZvwguplS"
      },
      "source": [
        "Here, We define the standalone `Generator` Model as follows:\n",
        "\n",
        "it takes a point from the latent space as input and generates a single 28×28 color image as output (the output dimension of mnist image). Initially, a fully connected layer interprets the latent space point and generates sufficient activations, which are then reshaped into multiple (in this case, 128) low-resolution versions of the output image (e.g., 7×7). These low-resolution images are then upsampled twice using transpose convolutional layers, doubling the size and quadrupling the area of the activations with each upsampling step.\n",
        "\n",
        "The generator could be modified with more complex structure (more conv layers) for high resolution images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjB5E1DjuplS"
      },
      "outputs": [],
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        " model = Sequential()\n",
        " # foundation for 7x7 image\n",
        " n_nodes = 128 * 7 * 7\n",
        " model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        " model.add(LeakyReLU(alpha=0.2))\n",
        " model.add(Reshape((7, 7, 128)))\n",
        " # upsample to 14x14\n",
        " model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        " model.add(LeakyReLU(alpha=0.2))\n",
        " # upsample to 28x28\n",
        " model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        " model.add(LeakyReLU(alpha=0.2))\n",
        " model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        " return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEU8BaXIuplS"
      },
      "source": [
        "The **define_gan()** function below takes as arguments the already-defined `generator and discriminator` models and creates the new logical third model subsuming these two models. The weights in the discriminator are marked as not trainable, which only affects the weights as seen by the GAN model and not the standalone discriminator model.\n",
        "\n",
        "The GAN model then uses the same binary cross entropy loss function as the discriminator and the efficient Adam version of stochastic gradient descent with the learning rate of 0.0002 and momentum 0.5, recommended when training deep convolutional GANs.\n",
        "Those parameters could be changed by different scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao91lFWAuplS"
      },
      "outputs": [],
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYDuKVZKuplT"
      },
      "source": [
        "Define the function for select the real images for `discriminator` to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "000L86bpuplT"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyZ9IpmKuplU"
      },
      "source": [
        "Define the function for giving input of `Generator`.\n",
        "The `x_input` is the random noise and used as the input for `Generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r68UY3NMuplU"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR4hGELluplU"
      },
      "source": [
        "Define the function for generating the `synthetic images` (fake one) and give the label for later `discriminator` usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N79vzY2IuplU"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "# create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, epoch, n=10):\n",
        " # plot images\n",
        " for i in range(n * n):\n",
        " # define subplot\n",
        "  pyplot.subplot(n, n, 1 + i)\n",
        " # turn off axis\n",
        "  pyplot.axis('off')\n",
        " # plot raw pixel data\n",
        "  pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        " # save plot to file\n",
        "  filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.close()"
      ],
      "metadata": {
        "id": "YaIbsQLagxG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Al5IO1uplV"
      },
      "source": [
        "Training for GAN usually takes a lot of epoches.\n",
        "Every few epoches, the performance of the `discriminator` will be evaluated. Idealy, if `discriminator` can not distinguish the true and fake images, then the GAN is well trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibxcu1U6uplV"
      },
      "outputs": [],
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        " # prepare real samples\n",
        " X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        " # evaluate discriminator on real examples\n",
        " _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        " # prepare fake examples\n",
        " x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        " # evaluate discriminator on fake examples\n",
        " _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        " # summarize discriminator performance\n",
        " print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        " # save plot\n",
        " save_plot(x_fake, epoch)\n",
        " # save the generator model tile file\n",
        " filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        " g_model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkB4XchcuplV"
      },
      "source": [
        "Define the overall training for the whole GAN including generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvzNj12auplV"
      },
      "outputs": [],
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_epochs):\n",
        "        # enumerate batches over the training set\n",
        "        for j in range(bat_per_epo):\n",
        "            # get randomly selected 'real' samples\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "            # generate 'fake' examples\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            # create training set for the discriminator\n",
        "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "            # update discriminator model weights\n",
        "            d_loss, _ = d_model.train_on_batch(X, y)\n",
        "            # prepare points in latent space as input for the generator\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            # create inverted labels for the fake samples\n",
        "            y_gan = ones((n_batch, 1))\n",
        "            # update the generator via the discriminator's error\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            # summarize loss on this batch\n",
        "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "        # evaluate the model performance, sometimes\n",
        "        if (i+1) % 10 == 0:\n",
        "            summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UeQAlFhuplV"
      },
      "source": [
        "<a id = \"cell_GAN_train\"></a>\n",
        "### 3. Train GAN model\n",
        "\n",
        "Before training the GAN model, the generator and discrimintor require to be defined.\n",
        "By viewing the GAN structure, what you could observe?\n",
        "\n",
        "\n",
        "\n",
        "1.   The generator and discriminator take turns for training, therefore, the loss will be back-propagate from discriminator to generator.\n",
        "2.   The GAN is a connected NN by combining the generator and discriminator.\n",
        "\n",
        "How does the GAN get optimized?\n",
        "\n",
        "\\begin{equation}\n",
        "\\min_G \\max_D V(D, G)\n",
        "\\end{equation}\n",
        "where :\n",
        "\\begin{equation}\n",
        "V(D, G) = \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\mathbf{x})} [\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}(\\mathbf{z})} [\\log (1 - D(G(\\mathbf{z})))]\n",
        "\\end{equation}\n",
        "\n",
        "Here, the x represents the real image sampled from the image database,\n",
        "the z represents the random noise. The G is the generator and D is the discriminator. The goal is for the generator to produce data that the discriminator cannot distinguish from real data, while the discriminator aims to correctly identify real versus generated data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK8g7PoluplV"
      },
      "outputs": [],
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# summarize gan models\n",
        "print(d_model.summary())\n",
        "print(g_model.summary())\n",
        "print(gan_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFimQ_yeuplW"
      },
      "source": [
        "Train the entire GAN model. ***This step will take around 15- 30 mins with GPU***.\n",
        "If you are not in GPU session, please skip to next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiSJwLjDuplW",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train(g_model=g_model, d_model=d_model, gan_model=gan_model, dataset=dataset, latent_dim=latent_dim,n_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUmzww6BuplX"
      },
      "source": [
        "\n",
        "<a id = \"cell_GAN_use\"></a>\n",
        "### 4. Image Generation with GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1kI9ypbuplX"
      },
      "source": [
        "Loading the generator model and generating new images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7LgbUPOuplX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# load model after 10 epoch\n",
        "model = load_model('generator_model_010.h5', compile=False)\n",
        "\n",
        "# generate images\n",
        "latent_points = generate_latent_points(latent_dim, 25)\n",
        "# generate images\n",
        "X = model.predict(latent_points)\n",
        "# plot the result\n",
        "show_images(X, 5)\n",
        "\n",
        "#Run the above cole multiple times to see different images being generated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model after 100 epoch\n",
        "model = load_model('generator_model_050.h5', compile=False)\n",
        "\n",
        "# generate images\n",
        "latent_points = generate_latent_points(latent_dim, 25)\n",
        "# generate images\n",
        "X = model.predict(latent_points)\n",
        "# plot the result\n",
        "show_images(X, 5)"
      ],
      "metadata": {
        "id": "9h5Dky0lJ5pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The synthetic mnist data from epoch 0 to 200**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1sK3EwgO0lTy0XSd4m8i3asA90kzMyEeu)"
      ],
      "metadata": {
        "id": "IbKqaoF63F4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many other GAN for image generation. Due to the limitation of GPU, we can not run big GAN as example here, but you could try later if you have more time.\n",
        "\n",
        "\n",
        "\n",
        "1.   Avatar GAN https://github.com/aakashjhawar/AvatarGAN/blob/master/README.md\n",
        "2.   PIX2PIX GAN https://github.com/phillipi/pix2pix\n",
        "\n",
        "1.   DCGAN https://github.com/carpedm20/DCGAN-tensorflow\n",
        "2.   CycleGAN https://github.com/junyanz/CycleGAN\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-nTxIG_V179F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avatar GAN Example from epoch 0 to 100 (50 mins to 1.5 hours training time)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1YBqlqL1N3gthVxJ8x5D6fP5FkKAbeWJi)"
      ],
      "metadata": {
        "id": "B9eorkMY38DC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21hm3JjEp5vN"
      },
      "source": [
        "**Reference:**\n",
        "\n",
        "Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2020). Generative adversarial networks. Communications of the ACM, 63(11), 139-144.\n",
        "\n",
        "*Also see: https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/*\n",
        "\n",
        "https://arxiv.org/abs/1406.2661"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}